{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d116768",
   "metadata": {},
   "source": [
    "# Image Recogniser Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e30e8",
   "metadata": {},
   "source": [
    "# 1. Overview:\n",
    "\n",
    "#### 1.1 Team:\n",
    "- Emma\n",
    "- Raphael\n",
    "\n",
    "#### 1.2 Topic:\n",
    "**Garbage Image Classification**\n",
    "##### 1.2.1 Objective:\n",
    "- Build model to classify different types of garbage (recycable, non-recycable) \n",
    "    - MVP: linear classifier, SVM, DF or pretrained CNN\n",
    "    - next level: self trained CNN\n",
    "- Dive into CNN\n",
    "- optional: create APP\n",
    "\n",
    "##### 1.2.2 Data:\n",
    "Collected by Gary Thung and Mindy Yang.\n",
    "The Dataset contains 2527 images of six classes of garbage deployed on plain background:\n",
    " - 501 glass\n",
    " - 594 paper\n",
    " - 403 cardboard\n",
    " - 482 plastic\n",
    " - 410 metal\n",
    " - 137 trash\n",
    "\n",
    "\n",
    "##### 1.2.3 Link to the Dataset:\n",
    "https://github.com/garythung/trashnet/blob/master/data/dataset-resized.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fdba6",
   "metadata": {},
   "source": [
    "## 2. Import libraries <a name=\"2\"></a>\n",
    "Import necessary libraries for data-handling, plotting, modeling.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a797cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "#import pytorch_lightning\n",
    "\n",
    "import pickle\n",
    "from tqdm import trange, tqdm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd64c4",
   "metadata": {},
   "source": [
    "## 3. Load data <a name=\"3\"></a>\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38106e37",
   "metadata": {},
   "source": [
    "#### 3.1 Load and transform data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53d1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = transforms.Compose([#transforms.RandomResizedCrop(224), \n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "#                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "\n",
    "data_set = datasets.ImageFolder(root='data/dataset-resized', transform=data_transformer)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(data_set, batch_size=36, shuffle=True)\n",
    "\n",
    "test_set, valid_set = torch.utils.data.random_split(data_set, (1769, 758))\n",
    "\n",
    "labels = data_set.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f111a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "097efc39",
   "metadata": {},
   "source": [
    "#### 3.2 Visualise transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57176e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "images, classes = next(iter(loader))\n",
    "\n",
    "# Make a grid from batch\n",
    "#batch_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "#imshow(batch_grid, title=[labels[x] for x in classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3014d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = torchvision.utils.make_grid(images, nrow=8)\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "\n",
    "# print('labels: ', [labels[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498ca42",
   "metadata": {},
   "source": [
    "## 4. Create model <a name=\"4\"></a>\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79fd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"model/resnet18.pickle\",\"rb\") as fp:\n",
    "        model = pickle.load(fp)\n",
    "except:\n",
    "    print(\"Couldn't find model\")\n",
    "    model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7870fc5",
   "metadata": {},
   "source": [
    "## 5. Train model <a name=\"5\"></a>\n",
    "Improve the training of the model using our own data set.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040eec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning parameters\n",
    "learn_rate = 1e-3\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3daaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the loss function (difference between likelihood of predicted label and actual label)\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # combination of mse and negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edcdc253",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.SGD(model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6873e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(loader, model, loss, optimiser):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch, (images, labels) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        loss = nn.functional.cross_entropy(pred, labels)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        print(f\"Batch {batch + 1} loss: {loss}\") \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Accumulated loss: {total_loss}\") \n",
    "\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f87343ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "------------------------\n",
      "Batch 1 loss: 0.6867982745170593\n",
      "Batch 2 loss: 0.5414140224456787\n",
      "Batch 3 loss: 0.4359928071498871\n",
      "Batch 4 loss: 0.8182901740074158\n",
      "Batch 5 loss: 0.6527044773101807\n",
      "Batch 6 loss: 0.3561745882034302\n",
      "Batch 7 loss: 0.45623859763145447\n",
      "Batch 8 loss: 0.5232836604118347\n",
      "Batch 9 loss: 1.0272841453552246\n",
      "Batch 10 loss: 0.6115518808364868\n",
      "Batch 11 loss: 0.6043291091918945\n",
      "Batch 12 loss: 0.7603785395622253\n",
      "Batch 13 loss: 0.6321735382080078\n",
      "Batch 14 loss: 0.5346982479095459\n",
      "Batch 15 loss: 0.46713292598724365\n",
      "Batch 16 loss: 0.5995666980743408\n",
      "Batch 17 loss: 0.5790975093841553\n",
      "Batch 18 loss: 0.6190906167030334\n",
      "Batch 19 loss: 0.5384702086448669\n",
      "Batch 20 loss: 0.578984797000885\n",
      "Batch 21 loss: 0.7049403786659241\n",
      "Batch 22 loss: 0.32998135685920715\n",
      "Batch 23 loss: 0.5392200946807861\n",
      "Batch 24 loss: 0.6354419589042664\n",
      "Batch 25 loss: 0.4477543234825134\n",
      "Batch 26 loss: 0.6336253881454468\n",
      "Batch 27 loss: 0.4891048073768616\n",
      "Batch 28 loss: 0.5785900354385376\n",
      "Batch 29 loss: 0.6765784025192261\n",
      "Batch 30 loss: 0.6482098698616028\n",
      "Batch 31 loss: 0.5404031872749329\n",
      "Batch 32 loss: 0.58206707239151\n",
      "Batch 33 loss: 0.6205354928970337\n",
      "Batch 34 loss: 0.5129890441894531\n",
      "Batch 35 loss: 0.4440864324569702\n",
      "Batch 36 loss: 0.7968893051147461\n",
      "Batch 37 loss: 0.6224619746208191\n",
      "Batch 38 loss: 0.5216119289398193\n",
      "Batch 39 loss: 0.6154752969741821\n",
      "Batch 40 loss: 0.5958817005157471\n",
      "Batch 41 loss: 0.6385093331336975\n",
      "Batch 42 loss: 0.4063141942024231\n",
      "Batch 43 loss: 0.5964643955230713\n",
      "Batch 44 loss: 0.682463526725769\n",
      "Batch 45 loss: 0.6458242535591125\n",
      "Batch 46 loss: 0.7674340605735779\n",
      "Batch 47 loss: 0.799083948135376\n",
      "Batch 48 loss: 0.5331352353096008\n",
      "Batch 49 loss: 0.5208662748336792\n",
      "Batch 50 loss: 0.7690157294273376\n",
      "Batch 51 loss: 0.3419843912124634\n",
      "Batch 52 loss: 0.6218833327293396\n",
      "Batch 53 loss: 0.6322803497314453\n",
      "Batch 54 loss: 0.4395931363105774\n",
      "Batch 55 loss: 0.5471620559692383\n",
      "Batch 56 loss: 0.596627950668335\n",
      "Batch 57 loss: 0.48474031686782837\n",
      "Batch 58 loss: 0.415361613035202\n",
      "Batch 59 loss: 0.452255517244339\n",
      "Batch 60 loss: 0.4691063463687897\n",
      "Batch 61 loss: 0.5101062655448914\n",
      "Batch 62 loss: 0.5076684951782227\n",
      "Batch 63 loss: 0.6949212551116943\n",
      "Batch 64 loss: 0.5453743934631348\n",
      "Batch 65 loss: 0.6656138896942139\n",
      "Batch 66 loss: 0.4898702800273895\n",
      "Batch 67 loss: 0.4148997664451599\n",
      "Batch 68 loss: 0.761826753616333\n",
      "Batch 69 loss: 0.8432976007461548\n",
      "Batch 70 loss: 0.47636646032333374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [19:17<9:19:32, 1157.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71 loss: 1.270774245262146\n",
      "Accumulated loss: 42.100328236818314\n",
      "\n",
      "Epoch 2\n",
      "------------------------\n",
      "Batch 1 loss: 0.46658769249916077\n",
      "Batch 2 loss: 0.6015125513076782\n",
      "Batch 3 loss: 0.49798691272735596\n",
      "Batch 4 loss: 0.5877109169960022\n",
      "Batch 5 loss: 0.612987756729126\n",
      "Batch 6 loss: 0.5670445561408997\n",
      "Batch 7 loss: 0.719629168510437\n",
      "Batch 8 loss: 0.40763962268829346\n",
      "Batch 9 loss: 0.44139301776885986\n",
      "Batch 10 loss: 0.40496835112571716\n",
      "Batch 11 loss: 0.5562834143638611\n",
      "Batch 12 loss: 0.5620580315589905\n",
      "Batch 13 loss: 0.3609175682067871\n",
      "Batch 14 loss: 0.6048715114593506\n",
      "Batch 15 loss: 0.5190971493721008\n",
      "Batch 16 loss: 0.553987979888916\n",
      "Batch 17 loss: 0.6544433832168579\n",
      "Batch 18 loss: 0.6230928897857666\n",
      "Batch 19 loss: 0.6637247204780579\n",
      "Batch 20 loss: 0.5681900978088379\n",
      "Batch 21 loss: 0.41524195671081543\n",
      "Batch 22 loss: 0.6177259087562561\n",
      "Batch 23 loss: 0.5049843788146973\n",
      "Batch 24 loss: 0.5302884578704834\n",
      "Batch 25 loss: 0.40644320845603943\n",
      "Batch 26 loss: 0.5283986926078796\n",
      "Batch 27 loss: 0.5305680632591248\n",
      "Batch 28 loss: 0.3740238547325134\n",
      "Batch 29 loss: 0.5163794755935669\n",
      "Batch 30 loss: 0.3665024936199188\n",
      "Batch 31 loss: 0.4885573387145996\n",
      "Batch 32 loss: 0.5867238640785217\n",
      "Batch 33 loss: 0.5639161467552185\n",
      "Batch 34 loss: 0.5841048359870911\n",
      "Batch 35 loss: 0.2984056770801544\n",
      "Batch 36 loss: 0.5531971454620361\n",
      "Batch 37 loss: 0.476012647151947\n",
      "Batch 38 loss: 0.5321398377418518\n",
      "Batch 39 loss: 0.5780372619628906\n",
      "Batch 40 loss: 0.7799224257469177\n",
      "Batch 41 loss: 0.6960686445236206\n",
      "Batch 42 loss: 0.36052843928337097\n",
      "Batch 43 loss: 0.459833562374115\n",
      "Batch 44 loss: 0.5827177166938782\n",
      "Batch 45 loss: 0.48095571994781494\n",
      "Batch 46 loss: 0.3290385603904724\n",
      "Batch 47 loss: 0.4476204514503479\n",
      "Batch 48 loss: 0.39320337772369385\n",
      "Batch 49 loss: 0.3986818194389343\n",
      "Batch 50 loss: 0.43471869826316833\n",
      "Batch 51 loss: 0.5350936055183411\n",
      "Batch 52 loss: 0.5262008905410767\n",
      "Batch 53 loss: 0.6829606890678406\n",
      "Batch 54 loss: 0.33744022250175476\n",
      "Batch 55 loss: 0.36547911167144775\n",
      "Batch 56 loss: 0.6508978009223938\n",
      "Batch 57 loss: 0.6401371359825134\n",
      "Batch 58 loss: 0.4173111915588379\n",
      "Batch 59 loss: 0.6328088045120239\n",
      "Batch 60 loss: 0.42475029826164246\n",
      "Batch 61 loss: 0.49292051792144775\n",
      "Batch 62 loss: 0.5701397657394409\n",
      "Batch 63 loss: 0.6422250866889954\n",
      "Batch 64 loss: 0.6798396110534668\n",
      "Batch 65 loss: 0.5934740900993347\n",
      "Batch 66 loss: 0.41969966888427734\n",
      "Batch 67 loss: 0.4342944622039795\n",
      "Batch 68 loss: 0.67079758644104\n",
      "Batch 69 loss: 0.48810407519340515\n",
      "Batch 70 loss: 0.5634270906448364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [37:25<8:41:11, 1116.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71 loss: 0.7433034181594849\n",
      "Accumulated loss: 37.30037307739258\n",
      "\n",
      "Epoch 3\n",
      "------------------------\n",
      "Batch 1 loss: 0.6008517146110535\n",
      "Batch 2 loss: 0.513059139251709\n",
      "Batch 3 loss: 0.23518654704093933\n",
      "Batch 4 loss: 0.3550821542739868\n",
      "Batch 5 loss: 0.5024459958076477\n",
      "Batch 6 loss: 0.50050950050354\n",
      "Batch 7 loss: 0.3933457136154175\n",
      "Batch 8 loss: 0.26374152302742004\n",
      "Batch 9 loss: 0.4982162117958069\n",
      "Batch 10 loss: 0.36653590202331543\n",
      "Batch 11 loss: 0.560908854007721\n",
      "Batch 12 loss: 0.4568091034889221\n",
      "Batch 13 loss: 0.39089906215667725\n",
      "Batch 14 loss: 0.5326294302940369\n",
      "Batch 15 loss: 0.4818178713321686\n",
      "Batch 16 loss: 0.2900155186653137\n",
      "Batch 17 loss: 0.6394191980361938\n",
      "Batch 18 loss: 0.5442581176757812\n",
      "Batch 19 loss: 0.4938892722129822\n",
      "Batch 20 loss: 0.5406458973884583\n",
      "Batch 21 loss: 0.29794231057167053\n",
      "Batch 22 loss: 0.722572922706604\n",
      "Batch 23 loss: 0.6269388198852539\n",
      "Batch 24 loss: 0.8066822290420532\n",
      "Batch 25 loss: 0.7128005623817444\n",
      "Batch 26 loss: 0.27626004815101624\n",
      "Batch 27 loss: 0.5435975193977356\n",
      "Batch 28 loss: 0.4299449920654297\n",
      "Batch 29 loss: 0.3677806258201599\n",
      "Batch 30 loss: 0.2612229585647583\n",
      "Batch 31 loss: 0.2216818779706955\n",
      "Batch 32 loss: 0.5652714371681213\n",
      "Batch 33 loss: 0.4652821123600006\n",
      "Batch 34 loss: 0.5373830199241638\n",
      "Batch 35 loss: 0.25441086292266846\n",
      "Batch 36 loss: 0.3843645453453064\n",
      "Batch 37 loss: 0.5130283236503601\n",
      "Batch 38 loss: 0.35221725702285767\n",
      "Batch 39 loss: 0.2749757170677185\n",
      "Batch 40 loss: 0.45976006984710693\n",
      "Batch 41 loss: 0.4815239906311035\n",
      "Batch 42 loss: 0.43863141536712646\n",
      "Batch 43 loss: 0.4758928120136261\n",
      "Batch 44 loss: 0.4727500379085541\n",
      "Batch 45 loss: 0.48521238565444946\n",
      "Batch 46 loss: 0.4925716817378998\n",
      "Batch 47 loss: 0.5786298513412476\n",
      "Batch 48 loss: 0.49319082498550415\n",
      "Batch 49 loss: 0.6418362259864807\n",
      "Batch 50 loss: 0.3864338994026184\n",
      "Batch 51 loss: 0.4173620939254761\n",
      "Batch 52 loss: 0.3691690266132355\n",
      "Batch 53 loss: 0.27408432960510254\n",
      "Batch 54 loss: 0.3621998429298401\n",
      "Batch 55 loss: 0.5271461606025696\n",
      "Batch 56 loss: 0.37954458594322205\n",
      "Batch 57 loss: 0.5931195020675659\n",
      "Batch 58 loss: 0.6190979480743408\n",
      "Batch 59 loss: 0.5704801082611084\n",
      "Batch 60 loss: 0.4460664391517639\n",
      "Batch 61 loss: 0.46974802017211914\n",
      "Batch 62 loss: 0.36218011379241943\n",
      "Batch 63 loss: 0.3373047113418579\n",
      "Batch 64 loss: 0.418204128742218\n",
      "Batch 65 loss: 0.34558799862861633\n",
      "Batch 66 loss: 0.3926246762275696\n",
      "Batch 67 loss: 0.49557510018348694\n",
      "Batch 68 loss: 0.4733368158340454\n",
      "Batch 69 loss: 0.4437604248523712\n",
      "Batch 70 loss: 0.4692983627319336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [11:50:54<142:56:11, 19058.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71 loss: 0.8716816306114197\n",
      "Accumulated loss: 32.81863008439541\n",
      "\n",
      "Epoch 4\n",
      "------------------------\n",
      "Batch 1 loss: 0.511759877204895\n",
      "Batch 2 loss: 0.3905051648616791\n",
      "Batch 3 loss: 0.44187837839126587\n",
      "Batch 4 loss: 0.5280813574790955\n",
      "Batch 5 loss: 0.5575722455978394\n",
      "Batch 6 loss: 0.39553844928741455\n",
      "Batch 7 loss: 0.5635295510292053\n",
      "Batch 8 loss: 0.5429761409759521\n",
      "Batch 9 loss: 0.4953882396221161\n",
      "Batch 10 loss: 0.2869512736797333\n",
      "Batch 11 loss: 0.617440402507782\n",
      "Batch 12 loss: 0.684714674949646\n",
      "Batch 13 loss: 0.4206211566925049\n",
      "Batch 14 loss: 0.3333183825016022\n",
      "Batch 15 loss: 0.6790034174919128\n",
      "Batch 16 loss: 0.31417274475097656\n",
      "Batch 17 loss: 0.435843825340271\n",
      "Batch 18 loss: 0.4426368772983551\n",
      "Batch 19 loss: 0.633439302444458\n",
      "Batch 20 loss: 0.256988525390625\n",
      "Batch 21 loss: 0.26989659667015076\n",
      "Batch 22 loss: 0.45568692684173584\n",
      "Batch 23 loss: 0.3705233633518219\n",
      "Batch 24 loss: 0.33448049426078796\n",
      "Batch 25 loss: 0.4585626423358917\n",
      "Batch 26 loss: 0.5318294763565063\n",
      "Batch 27 loss: 0.3732334077358246\n",
      "Batch 28 loss: 0.5069753527641296\n",
      "Batch 29 loss: 0.555777370929718\n",
      "Batch 30 loss: 0.379253625869751\n",
      "Batch 31 loss: 0.35846221446990967\n",
      "Batch 32 loss: 0.3371916711330414\n",
      "Batch 33 loss: 0.449785441160202\n",
      "Batch 34 loss: 0.3171166479587555\n",
      "Batch 35 loss: 0.4206511974334717\n",
      "Batch 36 loss: 0.4944569170475006\n",
      "Batch 37 loss: 0.39038729667663574\n",
      "Batch 38 loss: 0.3805904686450958\n",
      "Batch 39 loss: 0.40002110600471497\n",
      "Batch 40 loss: 0.2935086488723755\n",
      "Batch 41 loss: 0.5160912275314331\n",
      "Batch 42 loss: 0.47848087549209595\n",
      "Batch 43 loss: 0.3403237462043762\n",
      "Batch 44 loss: 0.43290382623672485\n",
      "Batch 45 loss: 0.5904941558837891\n",
      "Batch 46 loss: 0.3021555244922638\n",
      "Batch 47 loss: 0.4495285451412201\n",
      "Batch 48 loss: 0.48044314980506897\n",
      "Batch 49 loss: 0.38483425974845886\n",
      "Batch 50 loss: 0.4839059114456177\n",
      "Batch 51 loss: 0.29656779766082764\n",
      "Batch 52 loss: 0.3658008575439453\n",
      "Batch 53 loss: 0.46403583884239197\n",
      "Batch 54 loss: 0.3169153928756714\n",
      "Batch 55 loss: 0.3203096389770508\n",
      "Batch 56 loss: 0.40157967805862427\n",
      "Batch 57 loss: 0.4404451847076416\n",
      "Batch 58 loss: 0.5912964940071106\n",
      "Batch 59 loss: 0.31091219186782837\n",
      "Batch 60 loss: 0.3855830729007721\n",
      "Batch 61 loss: 0.22760576009750366\n",
      "Batch 62 loss: 0.42250552773475647\n",
      "Batch 63 loss: 0.5191363096237183\n",
      "Batch 64 loss: 0.7840359807014465\n",
      "Batch 65 loss: 0.24788840115070343\n",
      "Batch 66 loss: 0.18773578107357025\n",
      "Batch 67 loss: 0.5838531851768494\n",
      "Batch 68 loss: 0.2794361114501953\n",
      "Batch 69 loss: 0.23743626475334167\n",
      "Batch 70 loss: 0.29968103766441345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [12:10:16<86:37:00, 11993.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71 loss: 0.5144060254096985\n",
      "Accumulated loss: 30.26707860827446\n",
      "\n",
      "Epoch 5\n",
      "------------------------\n",
      "Batch 1 loss: 0.4141037166118622\n",
      "Batch 2 loss: 0.5380562543869019\n",
      "Batch 3 loss: 0.3907482922077179\n",
      "Batch 4 loss: 0.3425721228122711\n",
      "Batch 5 loss: 0.4089185893535614\n",
      "Batch 6 loss: 0.4251788854598999\n",
      "Batch 7 loss: 0.3137970268726349\n",
      "Batch 8 loss: 0.40187448263168335\n",
      "Batch 9 loss: 0.33579540252685547\n",
      "Batch 10 loss: 0.4969669580459595\n",
      "Batch 11 loss: 0.47049829363822937\n",
      "Batch 12 loss: 0.38666635751724243\n",
      "Batch 13 loss: 0.335449755191803\n",
      "Batch 14 loss: 0.4300288259983063\n",
      "Batch 15 loss: 0.3930479884147644\n",
      "Batch 16 loss: 0.28847137093544006\n",
      "Batch 17 loss: 0.3395904004573822\n",
      "Batch 18 loss: 0.358744740486145\n",
      "Batch 19 loss: 0.4070222079753876\n",
      "Batch 20 loss: 0.4098818898200989\n",
      "Batch 21 loss: 0.31509849429130554\n",
      "Batch 22 loss: 0.4184629023075104\n",
      "Batch 23 loss: 0.46934080123901367\n",
      "Batch 24 loss: 0.3574407398700714\n",
      "Batch 25 loss: 0.5192736983299255\n",
      "Batch 26 loss: 0.5122268199920654\n",
      "Batch 27 loss: 0.2188839316368103\n",
      "Batch 28 loss: 0.3798385560512543\n",
      "Batch 29 loss: 0.5063334107398987\n",
      "Batch 30 loss: 0.3649660050868988\n",
      "Batch 31 loss: 0.34933388233184814\n",
      "Batch 32 loss: 0.39033326506614685\n",
      "Batch 33 loss: 0.2632862329483032\n",
      "Batch 34 loss: 0.31985053420066833\n",
      "Batch 35 loss: 0.45846959948539734\n",
      "Batch 36 loss: 0.5316176414489746\n",
      "Batch 37 loss: 0.2526858448982239\n",
      "Batch 38 loss: 0.2678852081298828\n",
      "Batch 39 loss: 0.3394733667373657\n",
      "Batch 40 loss: 0.5490883588790894\n",
      "Batch 41 loss: 0.3029310703277588\n",
      "Batch 42 loss: 0.2359737753868103\n",
      "Batch 43 loss: 0.4437255263328552\n",
      "Batch 44 loss: 0.37509050965309143\n",
      "Batch 45 loss: 0.26380234956741333\n",
      "Batch 46 loss: 0.4641202688217163\n",
      "Batch 47 loss: 0.157304584980011\n",
      "Batch 48 loss: 0.3341136574745178\n",
      "Batch 49 loss: 0.343406081199646\n",
      "Batch 50 loss: 0.4754406213760376\n",
      "Batch 51 loss: 0.27746760845184326\n",
      "Batch 52 loss: 0.4766700565814972\n",
      "Batch 53 loss: 0.2613156735897064\n",
      "Batch 54 loss: 0.37475675344467163\n",
      "Batch 55 loss: 0.32928481698036194\n",
      "Batch 56 loss: 0.4020792245864868\n",
      "Batch 57 loss: 0.5179083347320557\n",
      "Batch 58 loss: 0.28987014293670654\n",
      "Batch 59 loss: 0.26381370425224304\n",
      "Batch 60 loss: 0.37574851512908936\n",
      "Batch 61 loss: 0.3611539304256439\n",
      "Batch 62 loss: 0.22532817721366882\n",
      "Batch 63 loss: 0.2711578607559204\n",
      "Batch 64 loss: 0.2986108958721161\n",
      "Batch 65 loss: 0.44377076625823975\n",
      "Batch 66 loss: 0.34017619490623474\n",
      "Batch 67 loss: 0.37028229236602783\n",
      "Batch 68 loss: 0.3199428915977478\n",
      "Batch 69 loss: 0.47423410415649414\n",
      "Batch 70 loss: 0.4800908863544464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [34:31:48<254:49:13, 36694.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 71 loss: 0.6442673802375793\n",
      "Accumulated loss: 26.86514151096344\n",
      "\n",
      "Epoch 6\n",
      "------------------------\n",
      "Batch 1 loss: 0.2861570715904236\n",
      "Batch 2 loss: 0.4272765517234802\n",
      "Batch 3 loss: 0.30218395590782166\n",
      "Batch 4 loss: 0.6334078311920166\n",
      "Batch 5 loss: 0.6856504678726196\n",
      "Batch 6 loss: 0.20052191615104675\n",
      "Batch 7 loss: 0.4158209562301636\n",
      "Batch 8 loss: 0.41207754611968994\n",
      "Batch 9 loss: 0.4084608256816864\n",
      "Batch 10 loss: 0.4034353494644165\n",
      "Batch 11 loss: 0.5223625302314758\n",
      "Batch 12 loss: 0.3256913721561432\n",
      "Batch 13 loss: 0.4545782506465912\n",
      "Batch 14 loss: 0.2193203568458557\n",
      "Batch 15 loss: 0.35408562421798706\n",
      "Batch 16 loss: 0.4419543147087097\n",
      "Batch 17 loss: 0.35356876254081726\n",
      "Batch 18 loss: 0.6239430904388428\n",
      "Batch 19 loss: 0.3421770930290222\n",
      "Batch 20 loss: 0.21873636543750763\n",
      "Batch 21 loss: 0.14537855982780457\n",
      "Batch 22 loss: 0.3503362238407135\n",
      "Batch 23 loss: 0.3073289096355438\n",
      "Batch 24 loss: 0.38601842522621155\n",
      "Batch 25 loss: 0.32272976636886597\n",
      "Batch 26 loss: 0.2556282579898834\n"
     ]
    }
   ],
   "source": [
    "for i in trange(epochs):\n",
    "    \n",
    "    print()\n",
    "    print(f\"Epoch {i+1}\\n------------------------\")\n",
    "    training_loop(loader, model, loss, optimiser)\n",
    "    with open('model/resnet18.pickle','wb') as fp:\n",
    "        pickle.dump(model, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2ed802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/resnet18.pickle','wb') as fp:\n",
    "    pickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1483d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3028fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "254d12c6",
   "metadata": {},
   "source": [
    "## 6. Visualise model predictions <a name=\"6\"></a>\n",
    "Import necessary libraries for data-handling, plotting, modeling.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26118bc2",
   "metadata": {},
   "source": [
    "## 7. Tune parameters <a name=\"7\"></a>\n",
    "Import necessary libraries for data-handling, plotting, modeling.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520976",
   "metadata": {},
   "source": [
    "## 8. Execute and evaluate <a name=\"8\"></a>\n",
    "Import necessary libraries for data-handling, plotting, modeling.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0ceb3",
   "metadata": {},
   "source": [
    "## 9. Create predictor function<a name=\"9\"></a>\n",
    "Import necessary libraries for data-handling, plotting, modeling.\n",
    "[↑ back to top ↑](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e828c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
